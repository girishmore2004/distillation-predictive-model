# -*- coding: utf-8 -*-
"""Q.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1INph__bhv9Tp4kUsGPLc-wWoYmCHbHLk

**Load and Explore the Data**
"""

import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Step 1: Load the data
file_path = 'Distillation Column Dataset.xlsx'
df = pd.read_excel(file_path)

# Display basic information about the dataset
df.info()

# Display the first few rows of the dataset
df.head()

# Check for missing values
df.isnull().sum()

# Display summary statistics
df.describe()

"""**Data Cleaning and Preprocessing**"""

# Step 2: Data Cleaning

# Drop columns with constant values (as they don't contribute to the model)
columns_to_drop = ['Sensor9', 'Sensor10', 'Sensor16']
df = df.drop(columns=columns_to_drop, axis=1)

# Rename columns for better readability (optional)
column_rename_map = {
    'Sensor1': 'Liquid%inCondensor',
    'Sensor2': 'Condenser_Pressure',
    'Sensor3': 'Liquid%inReboiler',
    'Sensor4': 'Mass_Flow_Rate_in_Feed_Flow',
    'Sensor5': 'Mass_Flow_Rate_in_Top_outlet_stream',
    'Sensor6': 'Net_Mass_Flow_in_main_tower',
    'Sensor7': 'Mole Fraction HX at reboiler',
    'Sensor8': 'HX Mole Fraction in Top Outler Stream',
    'Sensor11': 'Feed_Tray_Temp',
    'Sensor12': 'Main_Tower_Pressure',
    'Sensor13': 'Bottom Tower Pressure',
    'Sensor14': 'Top Tower Pressure',
    'Sensor15': 'Reflux_Ratio'
}
df.rename(columns=column_rename_map, inplace=True)

# Verify changes
df.head()

"""**Define Sensors and Target**"""

# Define the sensors and target properties
sensors = ['Liquid%inCondensor', 'Condenser_Pressure', 'Liquid%inReboiler', 'Mass_Flow_Rate_in_Feed_Flow', 'Mass_Flow_Rate_in_Top_outlet_stream', 'Net_Mass_Flow_in_main_tower','Mole Fraction HX at reboiler','HX Mole Fraction in Top Outler Stream', 'Feed_Tray_Temp', 'Main_Tower_Pressure','Bottom Tower Pressure','Top Tower Pressure','Reflux_Ratio']
target_properties = [ 'MoleFractionHX','MoleFractionTX']

"""**Plot Time Series for Each Sensor**"""

import pandas as pd
import matplotlib.pyplot as plt

# Dictionary to hold units for each sensor, including the new sensors
units = {
    'Liquid%inCondensor': '%',
    'Condenser_Pressure': 'Pa',  # Assuming pressure in Pascals
    'Liquid%inReboiler': '%',
    'Mass_Flow_Rate_in_Feed_Flow': 'kg/s',
    'Mass_Flow_Rate_in_Top_outlet_stream': 'kg/s',
    'Net_Mass_Flow_in_main_tower': 'kg/s',
    'Feed_Tray_Temp': 'Â°C',  # Assuming temperature in Celsius
    'Main_Tower_Pressure': 'Pa',  # Assuming pressure in Pascals
    'Mole Fraction HX at reboiler': '',
    'HX Mole Fraction in Top Outler Stream': '',
    'Bottom Tower Pressure': 'Pa',
    'Top Tower Pressure': 'Pa',
    'Reflux_Ratio': ''
}

# Updated list of sensors including the new ones
sensors = ['Liquid%inCondensor', 'Condenser_Pressure', 'Liquid%inReboiler',
           'Mass_Flow_Rate_in_Feed_Flow', 'Mass_Flow_Rate_in_Top_outlet_stream',
           'Net_Mass_Flow_in_main_tower', 'Mole Fraction HX at reboiler',
           'HX Mole Fraction in Top Outler Stream', 'Feed_Tray_Temp',
           'Main_Tower_Pressure', 'Bottom Tower Pressure', 'Top Tower Pressure',
           'Reflux_Ratio']

# Plotting the time series for each sensor with units and numbering the graphs
for i, sensor in enumerate(sensors, start=1):
    plt.figure(figsize=(10, 5))
    plt.plot(df.index, df[sensor], label=sensor, color='blue')
    plt.xlabel('Time (hours)')  # Assuming time is in hours, adjust if necessary
    plt.ylabel(f'{sensor} Sensor Reading ({units.get(sensor, "")})')  # Use dictionary for units

    # Add grid and legend
    plt.grid(True)
    plt.legend()

    # Title formatting and placement below the plot
    plt.suptitle(f'{i}. {sensor} vs Time', y=-0.05, fontweight='bold')  # Adjusted 'y' value for title placement
    plt.tight_layout()  # To ensure everything fits well within the plot area
    plt.show()

sns.pairplot(df[sensors], kind='scatter', diag_kind='hist', plot_kws={'alpha': 0.5})
plt.suptitle('Pairwise Scatter Plots of Sensor Readings', y=1.02)
plt.show()

"""**Correlation Matrix Heatmap**"""

correlation_matrix = df[sensors + target_properties].corr()

# Plot correlation matrix heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(
    correlation_matrix,
    annot=True,  # Display values in each cell
    cmap='coolwarm',
    fmt='.2f',  # Format for displaying values
    square=True,
    cbar_kws={"shrink": 0.8},  # Color bar settings
    vmin=-1, vmax=1  # Optional: Sets limits for color scale for better visualization
)
plt.title('Correlation Matrix Heatmap (Filtered Data)')
plt.show()

"""**Define Features and Targets**"""

X = df.drop(columns=['MoleFractionTX', 'MoleFractionHX'])
y_TX = df['MoleFractionTX']
y_HX = df['MoleFractionHX']

"""**Train-Test Split**"""

X_train, X_test, y_TX_train, y_TX_test, y_HX_train, y_HX_test = train_test_split(X, y_TX, y_HX, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""**Define Features and Targets**"""

target_scaler = StandardScaler()
y_TX_train_scaled = target_scaler.fit_transform(y_TX_train.values.reshape(-1, 1))
y_TX_test_scaled = target_scaler.transform(y_TX_test.values.reshape(-1, 1))
y_HX_train_scaled = target_scaler.fit_transform(y_HX_train.values.reshape(-1, 1))
y_HX_test_scaled = target_scaler.transform(y_HX_test.values.reshape(-1, 1))

"""**Model 1 - RandomForestRegressor (Training and Evaluation)**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score

# RandomForest for MoleFractionTX
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_TX_train)
y_TX_pred_rf = rf.predict(X_test_scaled)
TX_r2_rf = r2_score(y_TX_test, y_TX_pred_rf)

print(f"RandomForest Model for MoleFractionTX R^2: {TX_r2_rf}")

# RandomForest for MoleFractionHX
rf_HX = RandomForestRegressor(n_estimators=100, random_state=42)
rf_HX.fit(X_train_scaled, y_HX_train)
y_HX_pred_rf = rf_HX.predict(X_test_scaled)
HX_r2_rf = r2_score(y_HX_test, y_HX_pred_rf)

print(f"RandomForest Model for MoleFractionHX R^2: {HX_r2_rf}")

"""**Model 2 - LinearRegression (Training and Evaluation)**"""

from sklearn.linear_model import LinearRegression

# Linear Regression for MoleFractionTX
lin_reg = LinearRegression()
lin_reg.fit(X_train_scaled, y_TX_train)
y_TX_pred_lin = lin_reg.predict(X_test_scaled)
TX_r2_lin = r2_score(y_TX_test, y_TX_pred_lin)

print(f"Linear Regression Model for MoleFractionTX R^2: {TX_r2_lin}")

# Linear Regression for MoleFractionHX
lin_reg_HX = LinearRegression()
lin_reg_HX.fit(X_train_scaled, y_HX_train)
y_HX_pred_lin = lin_reg_HX.predict(X_test_scaled)
HX_r2_lin = r2_score(y_HX_test, y_HX_pred_lin)

print(f"Linear Regression Model for MoleFractionHX R^2: {HX_r2_lin}")

"""**Model 3 - K-Nearest Neighbors Regressor (Training and Evaluation)**"""

from sklearn.neighbors import KNeighborsRegressor

# KNN Regressor for MoleFractionTX
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train_scaled, y_TX_train)
y_TX_pred_knn = knn.predict(X_test_scaled)
TX_r2_knn = r2_score(y_TX_test, y_TX_pred_knn)

print(f"KNN Regressor Model for MoleFractionTX R^2: {TX_r2_knn}")

# KNN Regressor for MoleFractionHX
knn_HX = KNeighborsRegressor(n_neighbors=5)
knn_HX.fit(X_train_scaled, y_HX_train)
y_HX_pred_knn = knn_HX.predict(X_test_scaled)
HX_r2_knn = r2_score(y_HX_test, y_HX_pred_knn)

print(f"KNN Regressor Model for MoleFractionHX R^2: {HX_r2_knn}")

"""**Model 4- Neural Network Model**"""

# Define a simple neural network model for regression
def build_nn_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(input_shape,)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')  # Linear activation for regression output
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
    return model
# Build and train a neural network model for MoleFractionTX
model_tx = build_nn_model(X_train_scaled.shape[1])
model_tx.fit(X_train_scaled, y_TX_train, epochs=100, batch_size=16, validation_split=0.2, verbose=0)

# Build and train a neural network model for MoleFractionHX
model_hx = build_nn_model(X_train_scaled.shape[1])
model_hx.fit(X_train_scaled, y_HX_train, epochs=100, batch_size=16, validation_split=0.2, verbose=0)
# Evaluate the model performance on the test set
y_tx_pred = model_tx.predict(X_test_scaled)
y_hx_pred = model_hx.predict(X_test_scaled)

# Calculate Mean Absolute Error and Mean Squared Error for both predictions
mae_tx = mean_absolute_error(y_TX_test, y_tx_pred)
mse_tx = mean_squared_error(y_TX_test, y_tx_pred)

mae_hx = mean_absolute_error(y_HX_test, y_hx_pred)
mse_hx = mean_squared_error(y_HX_test, y_hx_pred)
# Calculate R^2 scores for Neural Network predictions
TX_r2_nn = r2_score(y_TX_test, y_tx_pred)
HX_r2_nn = r2_score(y_HX_test, y_hx_pred)
print(f'MoleFractionTX - MAE: {mae_tx}, MSE: {mse_tx}, R^2: {TX_r2_nn}')
print(f'MoleFractionHX - MAE: {mae_hx}, MSE: {mse_hx}, R^2: {HX_r2_nn}')

"""**Model Comparison and Selection**"""

from sklearn.metrics import r2_score



# Comparison for MoleFractionTX
TX_r2_scores = {
    'Linear Regression': TX_r2_lin,
    'K-Nearest Neighbors': TX_r2_knn,
    'Random Forest': TX_r2_rf,
    'Neural Network': TX_r2_nn  # Add Neural Network R^2 score
}
best_model_TX = max(TX_r2_scores, key=TX_r2_scores.get)
print(f"Best model for MoleFractionTX: {best_model_TX}")

# Comparison for MoleFractionHX
HX_r2_scores = {
    'Linear Regression': HX_r2_lin,
    'K-Nearest Neighbors': HX_r2_knn,
    'Random Forest': HX_r2_rf,
    'Neural Network': HX_r2_nn  # Add Neural Network R^2 score
}
best_model_HX = max(HX_r2_scores, key=HX_r2_scores.get)
print(f"Best model for MoleFractionHX: {best_model_HX}")

"""**Plot **"""

# Plot results for MoleFractionTX
plt.figure(figsize=(12, 6))

# Add Neural Network predictions for MoleFractionTX
plt.subplot(1, 2, 1)
plt.scatter(y_TX_test, y_TX_pred_lin, color='blue', label='Linear Regression')
plt.scatter(y_TX_test, y_TX_pred_knn, color='green', label='KNN')
plt.scatter(y_TX_test, y_TX_pred_rf, color='red', label='Random Forest')
plt.scatter(y_TX_test, y_tx_pred, color='gray', label='Neural Network')
plt.xlabel('True MoleFractionTX')
plt.ylabel('Predicted MoleFractionTX')
plt.title('MoleFractionTX Predictions')
plt.legend()

# Plot results for MoleFractionHX
plt.subplot(1, 2, 2)
plt.scatter(y_HX_test, y_HX_pred_lin, color='blue', label='Linear Regression')
plt.scatter(y_HX_test, y_HX_pred_knn, color='green', label='KNN')
plt.scatter(y_HX_test, y_HX_pred_rf, color='red', label='Random Forest')
plt.scatter(y_HX_test, y_hx_pred, color='gray', label='Neural Network')
plt.xlabel('True MoleFractionHX')
plt.ylabel('Predicted MoleFractionHX')
plt.title('MoleFractionHX Predictions')
plt.legend()

plt.tight_layout()
plt.show()

"""**Model Interpretation and Prediction**"""

# Prediction function with feature matching
def predict_mole_fractions(new_data):
    # Ensure new_data matches the feature columns of the trained model
    new_data = new_data.reindex(columns=X.columns, fill_value=0)  # X.columns should be the columns used for training

    # Scale the data
    new_data_scaled = scaler.transform(new_data)

    # Use the best model for MoleFractionTX
    if best_model_TX == 'Linear Regression':
        mole_fraction_TX = lin_reg.predict(new_data_scaled)
    elif best_model_TX == 'K-Nearest Neighbors':
        mole_fraction_TX = knn.predict(new_data_scaled)
    else:
        mole_fraction_TX = rf.predict(new_data_scaled)

    # Use the best model for MoleFractionHX
    if best_model_HX == 'Linear Regression':
        mole_fraction_HX = lin_reg_HX.predict(new_data_scaled)
    elif best_model_HX == 'K-Nearest Neighbors':
        mole_fraction_HX = knn_HX.predict(new_data_scaled)
    else:
        mole_fraction_HX = rf_HX.predict(new_data_scaled)

    return {
        'MoleFractionTX': mole_fraction_TX,
        'MoleFractionHX': mole_fraction_HX
    }

# Example prediction
new_data = pd.DataFrame({
    'Liquid%inCondensor': [50],
    'Condenser_Pressure': [101],
    'Liquid%inReboiler': [50],
    'Mass_Flow_Rate_in_Feed_Flow': [37],
    'Mass_Flow_Rate_in_Top_outlet_stream': [6700],
    'Net_Mass_Flow_in_main_tower': [2750],
    'Feed_Tray_Temp': [77],
    'Main_Tower_Pressure': [101],
    'Reflux_Ratio': [0.8]
})

# Ensure all columns match the training data columns
predicted_mole_fractions = predict_mole_fractions(new_data)
print("Predicted Mole Fractions for New Data:", predicted_mole_fractions)